cv.errors[j,i]=mean((Hitters$Salary[folds==j]-pred)^2)
}
}
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]]) ## extract formula
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=5
set.seed(1)
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19,dimnames=list(NULL,paste(1:19)))
for(j in 1:k){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,],nvmax=19)
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean((Hitters$Salary[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
which.min(mean.cv.errors)
set.seed(1)
train=sample(c(TRUE,FALSE),nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
val.errors=rep(NA,19)
for(i in 1:19){
coefi=coef(regfit.best ,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,which.min(val.errors))
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]]) ## extract formula
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
library(ISLR)
#fix(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters=na.omit(Hitters)
sum(is.na(Hitters))
library(leaps)
regfit.full=regsubsets(Salary~.,Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters,nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
reg.summary$rsq
set.seed(1)
train=sample(c(TRUE,FALSE),nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
val.errors=rep(NA,19)
for(i in 1:19){
coefi=coef(regfit.best ,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,which.min(val.errors))
set.seed(1)
train=sample(c(TRUE,FALSE),nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
val.errors=rep(NA,19)
for(i in 1:19){
pred=predict(regfit.best,Hitters,i)
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,which.min(val.errors))
set.seed(1)
train=sample(c(TRUE,FALSE),nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
val.errors=rep(NA,19)
for(i in 1:19){
pred=predict(regfit.best,Hitters[test,],i)
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
library(ISLR)
data(Hitters)
Hitters=na.omit(Hitters)
library(glmnet)
grid=10^seq(10,-2, length =100)
x=model.matrix(Salary~.,Hitters )[,-1]
y=Hitters$Salary
grid=10^seq(10,-2, length =100)
ridge.mod=glmnet (x,y,alpha=0, lambda=grid)
summary(ridge.mod)
plot(ridge.mod, xvar="lambda", label=T)
str(Hitters)
set.seed(1)
train=sample (1: nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train ,],y[ train],alpha=0, lambda =grid ,
thresh =1e-12)
ridge.pred=predict (ridge.mod ,s=4, newx=x[test ,])
mean((ridge.pred -y.test)^2)
ridge.mod=glmnet(x[train ,],y[ train],alpha=0, lambda =grid ,
thresh =1e-12)
ridge.pred=predict(ridge.mod ,s=50, newx=x[test ,])
mean((ridge.pred-y.test)^2)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
bestlam =cv.out$lambda .min
bestlam
ridge.pred=predict (ridge.mod ,s=0, newx=x[test ,], exact=T)
mean((ridge.pred -y.test)^2)
lm(y∼x, subset=train)
predict (ridge.mod ,s=0,exact=T,type=" coefficients")[1:20,]
ridge.pred=predict (ridge.mod ,s=0, newx=x[test ,], exact=T)
mean((ridge.pred -y.test)^2)
lm(y~x, subset=train)
predict (ridge.mod ,s=0,exact=T,type=" coefficients")[1:20,]
predict(ridge.mod ,s=0,exact=T,type="coefficients")[1:20,]
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
bestlam =cv.out$lambda .min
bestlam =cv.out$lambda.min
bestlam
?cv.glmnet
bestlam =cv.out$lambda.1se
bestlam
bestlam =cv.out$lambda.min
bestlam
oneSE =cv.out$lambda.1se
oneSE
summary(cv.out)
cv.out
ridge.pred=predict (ridge.mod ,s=oneSE ,newx=x[test ,])
mean((ridge.pred -y.test)^2)
cv.out
cv.out
lasso.mod=glmnet(x[train ,],y[ train],alpha=1, lambda =grid)
plot(lasso.mod)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=1)
plot(cv.out)
bestlam =cv.out$lambda .min
lasso.pred=predict (lasso.mod ,s=bestlam ,newx=x[test ,])
mean((lasso.pred -y.test)^2)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[ train],alpha=1)
plot(cv.out)
bestlam =cv.out$lambda.min
lasso.pred=predict(lasso.mod ,s=bestlam ,newx=x[test ,])
mean((lasso.pred-y.test)^2)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
oneSE=cv.out$lambda.1se
oneSE
ridge.pred=predict (ridge.mod ,s=oneSE ,newx=x[test ,])
mean((ridge.pred -y.test)^2)
out=glmnet (x,y,alpha=1, lambda=grid)
lasso.coef=predict (out ,type=" coefficients",s= bestlam) [1:20,]
lasso.coef
out=glmnet (x,y,alpha=1, lambda=grid)
lasso.coef=predict(out ,type=" oefficients",s= bestlam) [1:20,]
out=glmnet(x,y,alpha=1, lambda=grid)
lasso.coef=predict(out ,type=" oefficients",s= bestlam)[1:20,]
out=glmnet(x,y,alpha=1, lambda=grid)
lasso.coef=predict(out, type="coefficients",s= bestlam)[1:20,]
lasso.coef
lasso.coef[lasso.coef!=0]
cv.out
lasso.mod=glmnet(x[train ,],y[ train],alpha=1, lambda =grid)
plot(lasso.mod)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[ train],alpha=1)
cv.out
plot(cv.out)
bestlam =cv.out$lambda.min
lasso.pred=predict(lasso.mod ,s=129.9 ,newx=x[test ,])
mean((lasso.pred-y.test)^2)
out=glmnet(x,y,alpha=1, lambda=grid)
out
lasso.coef=predict(out, type="coefficients",s=129.9)[1:20,]
lasso.coef
lasso.coef[lasso.coef!=0]
sample_size = 10000
m=50
sample_size = 10000
m=50
x1 = rep(NA, sample_size) # initial number of particles in box A
x2 = rep(NA, sample_size) # initial number of particles in box B
x <- 1:50
x1[1]=5
x2[1]=m-x1[1]
for (i in 2:sample_size)
{
# randomly choose a number in [1,25]
k=sample(x,1)
if (k<=x1[i-1])    # k is euqal or less than x1, choose a particle from A, transfer to B
{x1[i]=x1[i-1]-1
x2[i]=x2[i-1]+1}
if (k>x1[i-1])      # k is larger than x1, choose a particle from B, transfer to A
{x1[i]=x1[i-1]+1
x2[i]=x2[i-1]-1}
}
sum(x1)/sample_size
hist(x1) # draw a histogram of x1
plot(density(x1))
hist(x1)
plot(density(x1))
hist(x1)
hist(x1)
lines(density(X), col="blue", lwd=2)
lines(density(x1), col="blue", lwd=2)
hist(x1, prob=TRUE, col="grey")
lines(density(x1), col="blue", lwd=2)
x1
View(x1)
x2 = rep(NA, sample_size)
x <- 1:50
View(x)
sample_size<-10000
mat1<-cbind(c((M+1),(1:M)),c((2:(M+1)),1))
mat1<-cbind(c((M+1),(1:M)),c((2:(M+1)),1))
tpm<-matrix(NA, nrow=M+1,ncol=M+1)
# Create TPM using the Ehrenfest Diffusion Process for (i in 1:(M+1)){
ai<-(M-(i-1))/M
tpm[i,]<-0
tpm[i,mat1[i,2]]<-ai
tpm[i,mat1[i,1]]<-1-ai
}
for (i in 1:(M+1)){
ai<-(M-(i-1))/M
tpm[i,]<-0
tpm[i,mat1[i,2]]<-ai
tpm[i,mat1[i,1]]<-1-ai
}
### Run simulation x<-vector("numeric");x[1]<-5 t<-0:(M)
for (i in 1:n){
x[i+1]<-sample(t,1,replace=FALSE, prob=tpm[(x[i]+1),]) }
#Plots
par(mfrow=c(2,2))
hist(x);plot.ts(x, main="Trace Plot")
plot(density(x), main="Approximate Density of Ehrenfest Diffusion Samples")
m<-50;
sample_size<-10000
mat1<-cbind(c((M+1),(1:M)),c((2:(M+1)),1))
tpm<-matrix(NA, nrow=M+1,ncol=M+1)
# Create TPM using the Ehrenfest Diffusion Process
for (i in 1:(M+1)){
ai<-(M-(i-1))/M
tpm[i,]<-0
tpm[i,mat1[i,2]]<-ai
tpm[i,mat1[i,1]]<-1-ai
}
m<-50
sample_size<-10000
mat1<-cbind(c((m+1),(1:m)),c((2:(m+1)),1))
tpm<-matrix(NA, nrow=m+1,ncol=m+1)
# Create TPM using the Ehrenfest Diffusion Process
for (i in 1:(m+1)){
ai<-(m-(i-1))/m
tpm[i,]<-0
tpm[i,mat1[i,2]]<-ai
tpm[i,mat1[i,1]]<-1-ai
}
### Run simulation x<-vector("numeric");x[1]<-5 t<-0:(M)
for (i in 1:sample_size){
x[i+1]<-sample(t,1,replace=FALSE, prob=tpm[(x[i]+1),]) }
# Initialization
m<-50
sample_size<-10000
mat1<-cbind(c((m+1),(1:m)),c((2:(m+1)),1))
tpm<-matrix(NA, nrow=m+1,ncol=m+1)
# Create TPM using the Ehrenfest Diffusion Process
for (i in 1:(m+1)){
ai<-(m-(i-1))/m
tpm[i,]<-0
tpm[i,mat1[i,2]]<-ai
tpm[i,mat1[i,1]]<-1-ai
}
### Run simulation
x<-vector("numeric")
x[1]<-5
t<-0:(m)
for (i in 1:sample_size){
x[i+1]<-sample(t,1,replace=FALSE, prob=tpm[(x[i]+1),]) }
#Plots
par(mfrow=c(2,2))
hist(x);plot.ts(x, main="Trace Plot")
plot(density(x), main="Approximate Density of Ehrenfest Diffusion Samples")
hist(x, prob=TRUE)
prob.vec <- c(1/2, 1/6, 1/3)
sum(prob.vec)
(5/6)^2
###############################################################
## example code for simulating a branching process
###############################################################
## generate next generation for a single individual
## with p0=1/4, p1=1/2, p2=1/4
## test code
prob.vec <- c(1/2, 1/6, 1/3)
sum(prob.vec)
foo <- rep(NA,10000)
for (i in 1:10000) {
foo[i] <- sample(c(0,1,2), 2, replace=FALSE, prob=prob.vec)
}
n.branch.proc <- 50   # number of branching processes simulated
max.gen <- 50000      # for computational convenience
# (this introduces a bias in the generation process)
extinction <- rep(0, n.branch.proc) # keep track of whether the process went extinct. 0=> did not go extinct, 1=> went extinct
processLen <- rep(NA, n.branch.proc) # keep track of length of processes generated
for (j in 1:n.branch.proc) { # number of branching process realizations
currgen <- 1 # start X_0 at 1
numgen <- 0 # number of generations
## keep repeating until the size of the generation is 0 and number of generations
## (max.gen) has not been attained
while ((currgen > 0) && (numgen < max.gen)) {
numgen <- numgen + 1 # increase the number of generations
newgen <- 0 # start new generation off at 0
for (i in 1:currgen) {
newgen <- newgen + sample(c(0,1,2), 2,replace=FALSE, prob=prob.vec)
}
currgen <- newgen # this becomes the current generation
#    cat(j, numgen, currgen, "\n")
}
if (newgen==0) {
extinction[j] <- 1 # it went extinct
}
processLen[j] <- numgen
cat("done with branching process",i,"which had length",numgen,"\n")
}
## count number of times the process reached (the artificially imposed) maximum length of MAXGENS
sum(processLen==max.gen)
## plot a histogram of the lengths before extinction (or before reaching MAXGENS)
hist(processLen, main="Lengths of branching process realizations")
sum(processLen==max.gen)
A = matrix(c(0.6,0.4,0.5,0.5), ncol=2,nrow=2, byrow=TRUE)
A
A^5
library(data.table)
mydat <- fread('http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat')
head(mydat)
View(mydat)
mydat <- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.data')
head(mydat)
View(mydat)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names')
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header = F)
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header = T)
View(names_ozone)
raw_ozone <- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.data', data.table=F)
View(mydat)
class(raw_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=-1)
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=+1)
View(names_ozone)
names_ozone <- names_ozone[-1,]
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=+1)
View(names_ozone)
names_ozone <- names_ozone[,-1]
View(names_ozone)
names_ozone <- names_ozone[,-1]
names_ozone <- names_ozone[,1]
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=+1)
names_ozone <- names_ozone[,1]
View(names_ozone)
names_ozone <- names_ozone[1]
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=+1)
names_ozone <- names_ozone[1:73,]
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, skip=-2)
View(names_ozone)
names_ozone <- names_ozone[-2]
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', data.table=F, drop=2)
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=F, drop=2)
View(names_ozone)
ozone <- rbind(names_ozone,raw_ozone)
raw_ozone <- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.data', data.table=F)
class(raw_ozone)
View(raw_ozone)
rm(list=ls())
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=T)
View(names_ozone)
names_ozone <- as.list(names_ozone)
class(names_ozone)
View(names_ozone)
names_ozone <- as.list(names_ozone)
class(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=T, drop=2)
names_ozone <- as.list(names_ozone)
class(names_ozone)
View(names_ozone)
str(names_ozone)
names_ozone <- rbind(names_ozone, “Date” = c(1, 1))
names_ozone <- rbind(names_ozone, “Date”))
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=T, drop=2)
names_ozone <- rbind(names_ozone, “Date”))
names_ozone <- rbind(names_ozone, Date))
names_ozone <- rbind(names_ozone, Date=c("Date"))
a < c("Date")
a < "Date"
a < Date
a < a
a <- Date
a <- c("Date")
a
names_ozone <- rbind(names_ozone, a)
a <- as.data.frame(c("Date"))
names_ozone <- rbind(names_ozone, a)
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=F, drop=2)
View(names_ozone)
class(names_ozone)
a <- as.data.frame(c("Date"))
names_ozone <- rbind(a, names_ozone)
View(names_ozone)
View(a)
names(a)[1] <- "Date"
View(Date)
View(a)
names_ozone <- rbind(a, names_ozone)
a <- as.data.frame(c("Date"))
names(a)[1] <- "Date:"
names_ozone <- rbind(a,names_ozone)
View(names_ozone)
names_ozone <- t(rbind(a,names_ozone))
View(names_ozone)
names_ozone<- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.names', header=T,data.table=F, drop=2)
a <- as.data.frame(c("Date"))
names(a)[1] <- "Date:"
names_ozone <- t(rbind(a,names_ozone))
View(names_ozone)
ozone <- rbind(names_ozone,raw_ozone)
raw_ozone <- fread('http://www.grappa.univ-lille3.fr/~torre/Recherche/Datasets/downloads/ozone/ozone.data', data.table=F)
ozone <- rbind(names_ozone,raw_ozone)
length(raw_ozone)
length(names_ozone)
View(raw_ozone)
n <- dim(seismic)[1]
p <- dim(seismic)[2]
library(data.table);library(car);library(lars);library(knitr);library(ISLR);library(leaps);library(glmnet);library(MASS);library(reshape);library(ggplot2);library(pROC)
setwd("/Users/benStraub/Desktop/557/Project-3")
seismic <- read.csv("seismic.csv")
seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]
for(i in c(1:3,8)){
seismic[,i] <- as.numeric(seismic[,i])
}
n <- dim(seismic)[1]
p <- dim(seismic)[2]
set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]
glm.train <- glm(class~., seismic.train, family=binomial)
#summary(glm.train)
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"
confusion1 <- table(glm.pred ,seismic.train$class)
#mean(glm.pred==seismic.train$class)
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")
sensitivity <- confusion1[2,2]/sum(confusion1[,2])
specificity <- confusion1[1,1]/sum(confusion1[,1])
#confusion1
#sensitivity
#specificity
glm.probs=predict(glm.train, seismic.test, type="response")
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"
confusion2 <- table(glm.pred, seismic.test$class)
#mean(glm.pred==seismic.test$class)
sensitivity <- confusion2[2,2]/sum(confusion2[,2])
specificity <- confusion2[1,1]/sum(confusion2[,1])
#confusion2
#sensitivity
#specificity
super <- cbind(confusion1,confusion2)
colnames(super) <- c("Train 0", "Train 1", "Test 0", "Test 1")
rownames(super) <- c("Predict 0", "Predict 1")
kable(super, caption="Training vs. Test for logistic regression")
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")
par(mfrow = c(1,1))
plot.roc(roc.Test, col="blue", auc.polygon=TRUE,main="ROC Curve", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Train, add=TRUE)
