---
title: "Project 3: Seismic Data"
author: "Ben Straub, Hillary Koch, Jiawei Huang, Arif Masrur"
date: "4/25/2017"
output: ioslides_presentation
---

```{r, echo=FALSE}
setwd("/Users/benStraub/Desktop/557/Project-3")
seismic <- read.csv("seismic.csv")
```

## What goes bump in the dark?

![setting up](images/mining.jpg)

## Overview

- Motivation/Interest for Data
- Model
- Log. Regression and Discriminant Analysis
- Boosting and Random Forest Classification
- Cluster Analysis Proposal

## 1. Model

- 19 variables for 2584 observations
- Using Step-wise regression, reduced to

$$class \sim \beta_0 + \beta_1\cdot genergy + \beta_2\cdot gpuls + \beta_3\cdot nbumps$$ 
$$+ \beta_4\cdot nbumps2 + \beta_5\cdot nbumps4 + \epsilon, \quad \epsilon \sim N(0,\sigma^2) $$

- Class is a binary variable.  
- 1 for hazardous seismic event.  170 events
- 0 for non-hazardous seismic event.  2414 events

## 2. Logistic Regression and Discriminant Analysis

- Logistic Regression
- LDA
- QDA
- RDA

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Configuring Space
#rm(list=ls())

# Loading packages into R
#install.packages("e1071")
library(data.table);library(car);library(lars);library(knitr);library(ISLR);library(leaps);library(glmnet);library(MASS);library(reshape);library(ggplot2);library(pROC);library(klaR);library(gridExtra);library(ROCR);library(e1071);library(gbm);library(randomForest);

#setwd("~/Box Sync/Skool/Spring 2017/557/Project-2-master")
#setwd("F:/Penn_State/Spring2017/STAT557/Workspace")
setwd("/Users/benStraub/Desktop/557/Project-3")
seismic <- read.csv("seismic.csv")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
##---------------------------------------------
## 
##---------------------------------------------

seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}
```

## 2.1 Logistic Regression 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=1.75}
##------------------------------------
## Setting up Test and Training Sets
##------------------------------------

# Divide into training and test
n <- dim(seismic)[1]
p <- dim(seismic)[2]

set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]

# Stating Timing Method
start.time <- proc.time()

##--------------------------------------------
## Logistic Regression - Pre-Model Selection
##--------------------------------------------

## Running full model on train data
glm.train <- glm(class~., seismic.train, family=binomial)

## Getting predictions for train data
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Train Roc Curve.  Plotted at the end
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

## Getting predictions for Test data
glm.probs=predict(glm.train, seismic.test, type="response")
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Test Roc Curve.  Plotted at the end
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

## Plotting Test and Train ROC with AUC
par(mfrow = c(1,4))
plot.roc(roc.Train, col="blue", auc.polygon=TRUE,main="Train-ROC-Full", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Test, col="red", auc.polygon=TRUE,main="Test-Roc-Full", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time

##--------------------------------------------
## Logistic Regression - Post-Variable Selection
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########

##  step-model on train data
glm.train <- glm(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, seismic.train, family=binomial)

##  predictions for train data
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Train Roc Curve.  Plotted at the end
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

#  Training step-model on Test Data
glm.probs=predict(glm.train, seismic.test, type="response")

## predictions for test data
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Test Roc Curve.  Plotted at the end
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

# Plotting Roc Curves for Model 1/Step-Model
plot.roc(roc.Train, col="blue", auc.polygon=TRUE,main="Train-ROC-Step", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Test, col="red", auc.polygon=TRUE,main="Test-ROC-Step", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```


```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
# All system times for Full, Step and Lasso
log.reg <- matrix(c(time1,time2,rate1.train,rate3.train,rate2.test,rate4.test),nrow=3,ncol=2, byrow=T)
colnames(log.reg) <- c("Full", "Step")
rownames(log.reg) <- c("Computing Time", "Train Error Rates", "Test Error Rates")
kable(log.reg, caption="Logistic Regression")
```

## 2.2 Linear Discriminant Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2,cache=T}

##--------------------------------------------
## Linear Discriminant Analysis - Full Model 
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

## Running full model on train data
lda.fit <- lda(class~., data = seismic, subset = train)

## Predictions for Train
lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(lda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,4))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train-Full")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(lda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test-Full")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time

##--------------------------------------------
## Linear Discriminant Analysis - Post-Variable Selection
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########

## Running Model 1/step model on train data
lda.fit <- lda(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic, subset = train)
lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.train,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(lda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train-Step")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.test,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(lda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test-Step")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
# All system times for Full, Step and Lasso
lda.times <- matrix(c(time1,time2,rate1.train,rate3.train,rate2.test,rate4.test),nrow=3,ncol=2, byrow=T)
colnames(lda.times) <- c("Full", "Step")
rownames(lda.times) <- c("Computing Time", "Train Error Rates", "Test Error Rates")
kable(lda.times, caption="Linear Discriminant Analysis")
```

## 2.3 Quadratic Discriminant Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, cache=T}
##--------------------------------------------
## Quadratic Discriminant Analysis - Full Model 
##--------------------------------------------

#Full Model not able to handle the multicollinearity of the data.
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', comment=NA, fig.height=2, cache=T}

##-----------------------------------------
## Fit QDA model after variable selection
##-----------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########
par(mfrow = c(1,4))

# Run Model 1 on Training Data
qda.fit <- qda(class ~ genergy + gpuls + nbumps + nbumps2 + nbumps4, data=seismic.train)
qda.pred=predict(qda.fit, seismic.train, type="response")
qda.class.train <- qda.pred$class
posterior.train <- qda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(qda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
qda.pred.test <- predict(qda.fit, seismic.test)
qda.class.test <- qda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(qda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time
```


```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
# All system times for Full, Step and Lasso
qda.times <- matrix(c("NA",time1,"NA",rate1.train,"NA",rate2.test),nrow=3,ncol=2, byrow=T)
colnames(qda.times) <- c("Full", "Step")
rownames(qda.times) <- c("Computing Time", "Train Error Rates", "Test Error Rates")
kable(qda.times, caption="Quadratic Discriminant Analysis")
```

## 2.4 Regularized Discriminant Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
##--------------------------------------------
## Regularized Discriminant Analysis - Full Model 
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

rda.fit <- rda(class~., data=seismic.train)

## Using FULL model on TRAIN Data
rda.pred=predict(rda.fit, seismic.train, type="response")
rda.class.train <- rda.pred$class
posterior.train <- rda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(rda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,4))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train-Full")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
rda.pred.test <- predict(rda.fit, seismic.test)
rda.class.test <- rda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(rda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test-Full")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########
# Stating Timing Method
start.time <- proc.time()

rda.fit <- rda(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data=seismic.train)

## Using FULL model on TRAIN Data
rda.pred=predict(rda.fit, seismic.train, type="response")
rda.class.train <- rda.pred$class
posterior.train <- rda.pred$posterior
truth.train <- seismic.train$class


# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.train,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(rda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train-Step")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
rda.pred.test <- predict(rda.fit, seismic.test)
rda.class.test <- rda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.test,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

#rate4.test

## Roc Curve setup
pred <- prediction(rda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test-Step")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
# All system times for Full, Step and Lasso
rda.times <- matrix(c(time1,time2,rate1.train,rate3.train,rate2.test,rate4.test),nrow=3,ncol=2, byrow=T)
colnames(rda.times) <- c("Full", "Step")
rownames(rda.times) <- c("Computing Time", "Train Error Rates", "Test Error Rates")
kable(rda.times, caption="Regularized Discriminant Analysis")

```

## 2.5 Take Aways from Log. Regression and Discriminant Analysis

- Logistic performs the best out of all the methods.  
- LDA has similar results, but results in more computing time.
- QDA performs poorly on the full model

# 3 Boosting and Random Forest Classification

## 3.1 Boosting

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.align='center', fig.height=2, cache=T, results = 'hide'}
library(gbm)
#run boosting
start.time <- proc.time()

boost.seismic =gbm(class~.,data=seismic.train, distribution="bernoulli",n.trees =5000, interaction.depth =4)

## From the relative influence plot, we can see that genergy and energy are the two most important variables in boosting.

#summary(boost.seismic)

## on train dataset
#predict on the train dataset
yhat.boost.train=predict(boost.seismic,newdata =seismic.train,n.trees =5000,type="response")
#yhat.boost.train

#round to 0 and 1
yhat.boost.train.round=round(yhat.boost.train)
#yhat.boost.train.round

#roc curve on train dataset
roc.Train <- roc(seismic.train$class, yhat.boost.train, direction = "<")

par(mfrow = c(1,4))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Train data, full model", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

## on test dataset

#predict on the test dataset
yhat.boost.test=predict (boost.seismic,newdata =seismic.test,n.trees =5000,type="response")
#yhat.boost.test

#round to 0 and 1
yhat.boost.test.round=round(yhat.boost.test)
#yhat.boost.test.round

#roc curve on test dataset

roc.Test<- roc(seismic.test$class, yhat.boost.test, direction = "<")

plot.roc(roc.Test, col = "blue", auc.polygon = TRUE, main = "Test data, full model", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

# Misclassification rate (FP+FN)/total 
confusion <- table(yhat.boost.test.round,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)
#rate2.test

total.time <- proc.time() - start.time
time8 <- total.time[3] 
#time8

```

|*Table 5 Boosting*       || ||
|:------|-------:|-----:|
|*model*|Full model|Stepwise model|
|*time*  |10.38   |5.64|
|*misclassification rate*|.057|.060|

## 3.2 Random Forest Classification

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T,results='hide'}

## Setting data again for RF classifcation, as response variable has to be converted into "categorical" 
seismic <- read.csv("seismic.csv")
par(mfrow=c(1,2))
seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}

# Make response variable "categorical" for RF classification 
seismic$class = as.factor(seismic$class)

# Setting train and test dataset 
n <- dim(seismic)[1]
p <- dim(seismic)[2]
set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T,results='hide'}
library(randomForest)
start.time <- proc.time()

#------------------------------------------------------------------------------
## Tune the RF: Finding optimul numbers of variables for splitting on each node
#------------------------------------------------------------------------------
bestmtry <- tuneRF(seismic.train[-16], seismic.train$class, ntreeTry=100, 
     stepFactor=1.5,improve=0.01, dobest=FALSE, plot = F)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T,results='hide'}
## RF on Training Data 

rf.seismic = randomForest(class~., data = seismic.train, mtry=2, ntree=1000, importance = TRUE)
yhat.rf.train = predict(rf.seismic, type = "prob", newdata = seismic.train)[,2]

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.height=2, cache=T}
par(mfrow = c(1,4))

# ROC curve
roc.Train <- roc(seismic.train$class, yhat.rf.train, direction = "<")
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Full model, train", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

# Misclassification rate (FP+FN)/total
confusion <- table(yhat.rf.train, seismic.train$class)
train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
train.error = round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)
#train.error
#train.accuracy

## RF on Test Data 

yhat.rf.test = predict(rf.seismic, type = "prob", newdata = seismic.test)[,2]
roc.test <- roc(seismic.test$class, yhat.rf.test, direction = "<")

# ROC curve 
plot.roc(roc.test, col = "blue", auc.polygon = TRUE, main = "Full model, test", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

# Misclassification rate (FP+FN)/total
confusion <- table(yhat.rf.test, seismic.test$class)
test.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.test)
test.error = round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)
#test.error
#test.accuracy
#importance(rf.seismic)
#varImpPlot(rf.seismic)

total.time <- proc.time() - start.time
time7 <- total.time[3] 
#time7

#--------------------------------------------------------
## Stepwise Model = genergy + gpuls + nbumps + nbumps2 + nbumps4
#--------------------------------------------------------

## RF on Training Data

start.time <- proc.time()

rf.seismic = randomForest(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic.train, mtry=2, ntree=1000, importance = TRUE)
yhat.rf.train = predict(rf.seismic, type = "prob", newdata = seismic.train)[,2]
roc.Train <- roc(seismic.train$class, yhat.rf.train, direction = "<")

# ROC curve 
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Stepwise model, train", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

# Misclassification rate (FP+FN)/total
confusion <- table(yhat.rf.train, seismic.train$class)
train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
train.error = round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)
#train.error
#train.accuracy

## RF on Test Data
yhat.rf.test = predict(rf.seismic, type = "prob", newdata = seismic.test)[,2]
roc.test <- roc(seismic.test$class, yhat.rf.test, direction = "<")

# ROC curve 
plot.roc(roc.test, col = "blue", auc.polygon = TRUE, main = "Stepwise model, test", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

# Misclassification rate (FP+FN)/total
confusion <- table(yhat.rf.test, seismic.test$class)
test.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.test)
test.error = round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)
#test.error
#test.accuracy

total.time <- proc.time() - start.time
time8 <- total.time[3] 
#time8

```

## 3.2 Random Forest Classification

| RF on Models| Error Rate|Important Variable(s) |
|:--------------|-----------------:|------:|-------------------------------------:|
|Full Model (Train)| 9.4%| nbumps2,3,4 , genergy, nbumps, maxenergy, gdenergy, gpuls, and energy |
|Full Model (Test)| 5.7%| nbumps2,3,4 , genergy, nbumps, maxenergy, gdenergy, gpuls, and energy|
|Stepwise model (Train)|10% | nbumps and nbumps4|
|Stepwise model (Test)| 7.8%|nbumps and nbumps4 |

|:--------------|-----------------:|------:|
|Time elasped| Full Model: 5.09 |Stepwise Model: 1.90|

## 4. Cluster Analysis Proposal

-
-
-

https://knowledgepit.fedcsis.org/contest/view.php?id=112


