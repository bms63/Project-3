---
title: "557_Project"
author: "Ben Straub"
date: "4/11/2017"
output: pdf_document
---

# Data overview  
 
Mining activity has long been associated with mining hazards, such as fires, floods, and toxic contaminants (Dozolme, P., 2016). Among these hazards, seismic hazards are the hardest to detect and predict (Sikora & Wróbel, 2010). Minimizing loss from seismic hazards requires both advanced data collection and analysis. In recent years, more and more advanced seismic and seismoacoustic monitoring systems have come about. Still, the disproportionate number of low-energy versus high-energy seismic phenomena (e.g. > $10^4$J) renders traditional analysis methods insufficient.

In this project, we used the seismic-bumps dataset provided by Sikora & Wróbel (2010), found in the UCI Machine Learning Repository. This seismic-bumps dataset comes from a coal mine located in Poland and contains 2584 observations of 19 attributes. Each observation summarizes seismic activity in the rock mass within one 8-hour shift. Note that the decision attribute, named "class", has values 1 and 0. This variable is the response variable we use in this project. A class value of "1" is categorized as "hazardous state", which essentially indicates a registered seismic bump with high energy (>$10^4$J) in the next shift. A class value "0" represents non-hazardous state in the next shift. According to Bukowska (2006), a number of factors having an effect on seismic hazard occurrence were proposed. Among other factors, the occurrence of tremors with energy > $10^4$J was listed. The purpose is to find whether and how the other 18 variables can be used to determine the hazard status of the mine.

### Table 1. Attribute information of the seismic-bumps dataset

 | Data Attributes | Description | Data Types | 
| -----------|-------------------------------------------------|----------|
| seismic   | result of shift seismic hazard assessment: 'a' - lack of hazard, 'b' - low hazard, 'c' - high hazard, 'd' - danger state  | Categorical   |
| seismoacoustic | result of shift seismic hazard assessment | Categorical  | 
| shift  | type of a shift: 'W' - coal-getting, 'N' - preparation shift  | Categorical  | 
| genergy  | seismic energy recorded within previous shift by active geophones (GMax) monitoring the longwall | Continuous  | 
| gpuls  | number of pulses recorded within previous shift by GMax | Continuous |
| gdenergy  | deviation of recorded energy within previous shift from average energy recorded during eight previous shifts  | Continuous  | 
| gdpuls | deviation of recorded pulses within previous shift from average number of pulses recorded during eight previous shifts  | Continuous  | 
| ghazard  | result of shift seismic hazard assessment by the seismoacoustic method based on registration coming from GMax  | Categorical | 
| nbumps   | the number of seismic bumps recorded within previous shift | Continuous  | 
| nbumps$i$, $i\in\{1,\ldots,5\}$  | the number of seismic bumps ($10^i-10^{i+1}$ J) registered within previous shift | Continuous  | 
| energy   | total energy of seismic bumps registered within previous shift  | Continuous  | 
| maxenergy  | maximum energy of the seismic bumps registered within previous shift  | Continuous  | 
| class  | the decision attribute: '1' - high energy seismic bump occurred in the next shift ('hazardous state'), '0' - no high energy seismic bumps occurred in th next shift ('non-hazardous state') | Categorical   | 


```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Configuring Space
rm(list=ls())

# Loading packages into R
library(data.table);library(car);library(lars);library(knitr);library(ISLR);library(leaps);library(glmnet);library(MASS);library(reshape);library(ggplot2);library(pROC);library(klaR);library(gridExtra);library(ROCR);library(e1071);library(gbm);library(randomForest)



#setwd("~/Box Sync/Skool/Spring 2017/557/Project-2-master")
#setwd("F:/Penn_State/Spring2017/STAT557/Workspace")
setwd("/Users/benStraub/Desktop/557/Project-3")
seismic <- read.csv("seismic.csv")
```


# Exploratory Data Analysis 
 
The state of the mine was indeed deemed hazardous infrequently $-$ only 170 shifts out of 2584 $-$ a difficult problem in our analyses. We want to examine which observations of seismic activity can help in the prediction of the hazard state of the mine during the next shift. Regression diagnostics indicate that the data, in general, meet most assumptions. However, we see that that data are somewhat skewed right, and there is severe multicollinearity (VIF > 10) between some of the covariates, as shown below.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3}
##---------------------------------------------
## 
##---------------------------------------------

par(mfrow=c(1,2))

seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}

```

# Classification before Variable Selection 

We first take the seismic-bumps dataset and partition the data into training (75%) and test (25%) datasets. The next steps involve examining multiple classification methods on the training and test datasets separately. The goal is to examine which classification method outputs comparatively better prediction for seismic hazards based on available predictors.

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##------------------------------------
## Setting up Test and Training Sets
##------------------------------------

# Divide into training and test
n <- dim(seismic)[1]
p <- dim(seismic)[2]

set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]

```

# Logistic Regression

## Full Model

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

# Stating Timing Method
start.time <- proc.time()

##--------------------------------------------
## Logistic Regression - Pre-Model Selection
##--------------------------------------------

## Running full model on train data
glm.train <- glm(class~., seismic.train, family=binomial)

## Getting predictions for train data
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Train Roc Curve.  Plotted at the end
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

## Getting predictions for Test data
glm.probs=predict(glm.train, seismic.test, type="response")
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Test Roc Curve.  Plotted at the end
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

## Plotting Test and Train ROC with AUC
par(mfrow = c(1,2))
plot.roc(roc.Train, col="blue", auc.polygon=TRUE,main="Train-ROC-Full", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Test, col="red", auc.polygon=TRUE,main="Test-Roc-Full", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time
```

## Logistic Regression - Step Model

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##--------------------------------------------
## Logistic Regression - Post-Variable Selection
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########

##  step-model on train data
glm.train <- glm(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, seismic.train, family=binomial)

##  predictions for train data
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Train Roc Curve.  Plotted at the end
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

#  Training step-model on Test Data
glm.probs=predict(glm.train, seismic.test, type="response")

## predictions for test data
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Test Roc Curve.  Plotted at the end
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

# Plotting Roc Curves for Model 1/Step-Model
par(mfrow = c(1,2))
plot.roc(roc.Train, col="blue", auc.polygon=TRUE,main="Train-ROC-Step", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Test, col="red", auc.polygon=TRUE,main="Test-ROC-Step", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```

## Logistic Regression - Lasso Model

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
###########
# Model 2=seismic+shift+gpuls+nbumps
# LASSO Variable Selection
###########

## Stating Timing Method
start.time <- proc.time()

## Lasso-model on train data
glm.train <- glm(class~seismic+shift+gpuls+nbumps, seismic.train, family=binomial)

##  predictions for train data
glm.probs=predict(glm.train, type="response")
glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.train$class)
rate5.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Train Roc Curve.  Plotted at the end
roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

# Using Training Model2-Lasso model on Test Data
glm.probs=predict(glm.train, seismic.test, type="response")

## predictions for test data
glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"

# misclassification rate (FP+FN)/total
confusion <- table(glm.pred ,seismic.test$class)
rate6.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Test Roc Curve.  Plotted at the end
roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

# Plotting Roc Curves for Model 2
par(mfrow = c(1,2))
plot.roc(roc.Train, col="blue", auc.polygon=TRUE,main="Train-ROC-Lasso", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Test, col="red", auc.polygon=TRUE,main="Test-ROC-Lasso", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)

# Total time for this method
total.time <- proc.time() - start.time
time3 <- total.time[3] # the elapsed time

# All system times for Full, Step and Lasso
log.reg.times <- cbind(time1,time2, time3)
log.reg.times

# All missclassification rates for Logistic Regression
log.reg.rates.train <- cbind(rate1.train,rate3.train,rate5.train)
log.reg.rates.train
log.reg.rates.test <- cbind(rate2.test,rate4.test,rate6.test)
log.reg.rates.test
```

# Linear Discriminant Analysis

## Full Model

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##--------------------------------------------
## Linear Discriminant Analysis - Full Model 
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

## Running full model on train data
lda.fit <- lda(class~., data = seismic, subset = train)

## Predictions for Train
lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(lda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train-ROC-Full")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(lda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test-ROC-Full")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time
```

## Linear Discriminant Analysis - Step

```{r, echo = F, message = F, comment = NA}
##--------------------------------------------
## Linear Discriminant Analysis - Post-Variable Selection
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########

## Running Model 1/step model on train data
lda.fit <- lda(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic, subset = train)
lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.train,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(lda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.test,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(lda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```

## Linear Discriminant Analysis - Lasso

```{r, echo = F, message = F, comment = NA}
###########
# Model 2=seismic+shift+gpuls+nbumps
# LASSO Variable Selection
###########

# Stating Timing Method
start.time <- proc.time()

lda.fit <- lda(class~seismic+shift+gpuls+nbumps, data = seismic, subset = train)
lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.train,seismic.train$class)
rate5.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(lda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(lda.class.test,seismic.test$class)
rate6.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(lda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time3 <- total.time[3] # the elapsed time

# All system times for Full, Step and Lasso
lda.times <- cbind(time1,time2, time3)
lda.times

# All missclassification rates for Logistic Regression
lda.rates.train <- cbind(rate1.train,rate3.train,rate5.train)
lda.rates.train
lda.rates.test <- cbind(rate2.test,rate4.test,rate6.test)
lda.rates.test
```

# Quadratic Discriminant Analysis

## Full Model

Full Model not able to handle the multicollinearity of the data.

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##--------------------------------------------
## Linear Discriminant Analysis - Full Model 
##--------------------------------------------

#Full Model not able to handle the multicollinearity of the data.
```

## Quadratic Discriminant Analysis - Step

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##-----------------------------------------
## Fit QDA model after variable selection
##-----------------------------------------

# Stating Timing Method
start.time <- proc.time()

###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########

# Run Model 1 on Training Data
qda.fit <- qda(class ~ genergy + gpuls + nbumps + nbumps2 + nbumps4, data=seismic.train)
qda.pred=predict(qda.fit, seismic.train, type="response")
qda.class.train <- qda.pred$class
posterior.train <- qda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(qda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
qda.pred.test <- predict(qda.fit, seismic.test)
qda.class.test <- qda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(qda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time

```

## Quadratic Discriminant Analysis - LASSO

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
###########
# Model 2=seismic+shift+gpuls+nbumps
# LASSO Variable Selection
###########

# Stating Timing Method
start.time <- proc.time()

# Run Model 1 on Training Data
qda.fit <- qda(class ~ seismic+shift+gpuls+nbumps, data=seismic.train)
qda.pred=predict(qda.fit, seismic.train, type="response")
qda.class.train <- qda.pred$class
posterior.train <- qda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.train,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(qda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
qda.pred.test <- predict(qda.fit, seismic.test)
qda.class.test <- qda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(qda.class.test,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(qda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time

# All system times for Full, Step and Lasso
qda.times <- cbind(time1,time2)
qda.times

# All missclassification rates for Logistic Regression
qda.rates.train <- cbind(rate1.train,rate3.train,rate5.train)
qda.rates.train
qda.rates.test <- cbind(rate2.test,rate4.test,rate6.test)
qda.rates.test
```

# Regularized 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##--------------------------------------------
## Regularized Discriminant Analysis - Full Model 
##--------------------------------------------

# Stating Timing Method
start.time <- proc.time()

rda.fit <- rda(class~., data=seismic.train)

## Using FULL model on TRAIN Data
rda.pred=predict(rda.fit, seismic.train, type="response")
rda.class.train <- rda.pred$class
posterior.train <- rda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.train,seismic.train$class)
rate1.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(rda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
rda.pred.test <- predict(rda.fit, seismic.test)
rda.class.test <- rda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.test,seismic.test$class)
rate2.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(rda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time1 <- total.time[3] # the elapsed time
```

## Regularized Discriminant Analysis - Step

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
###########
# Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
# Step Variable Selection
###########
# Stating Timing Method
start.time <- proc.time()

rda.fit <- rda(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data=seismic.train)

## Using FULL model on TRAIN Data
rda.pred=predict(rda.fit, seismic.train, type="response")
rda.class.train <- rda.pred$class
posterior.train <- rda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.train,seismic.train$class)
rate3.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(rda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
rda.pred.test <- predict(rda.fit, seismic.test)
rda.class.test <- rda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.test,seismic.test$class)
rate4.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(rda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time2 <- total.time[3] # the elapsed time
```

## Regularized Discriminant Analysis - Lasso

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
###########
# Model 2=seismic+shift+gpuls+nbumps
# LASSO Variable Selection
###########
# Stating Timing Method
start.time <- proc.time()
rda.fit <- rda(class~seismic+shift+gpuls+nbumps, data=seismic.train)

## Using FULL model on TRAIN Data
rda.pred=predict(rda.fit, seismic.train, type="response")
rda.class.train <- rda.pred$class
posterior.train <- rda.pred$posterior
truth.train <- seismic.train$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.train,seismic.train$class)
rate5.train <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc curve setup
pred <- prediction(rda.pred$posterior[,2], seismic.train$class) 
perf_train <- performance(pred,"tpr","fpr")

par(mfrow = c(1,2))

## Roc Curve for Training
plot(perf_train,colorize=TRUE, main="Train")
abline(a=0, b= 1)
perf_train <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_train@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

## Prediction for Test
rda.pred.test <- predict(rda.fit, seismic.test)
rda.class.test <- rda.pred.test$class

# Misclassification rate (FP+FN)/total
confusion <- table(rda.class.test,seismic.test$class)
rate6.test <- round((confusion[2,1]+confusion[1,2])/(sum(confusion[,1])+sum(confusion[,2])),3)

## Roc Curve setup
pred <- prediction(rda.pred.test$posterior[,2], seismic.test$class) 
perf_test <- performance(pred,"tpr","fpr")

#Roc Curve for Test
plot(perf_test,colorize=TRUE, main="Test")
abline(a=0, b= 1)
perf_test <- performance(pred,"tpr","fpr",measure="auc")
auc <- round(as.numeric(perf_test@y.values),5)
text(0.75, 0.25, auc, cex = .8)
text(0.75, 0.35, "AUC", cex = .8)

# Total time for this method
total.time <- proc.time() - start.time
time3 <- total.time[3] # the elapsed time

# All system times for Full, Step and Lasso
rda.times <- cbind(time1,time2)
rda.times

# All missclassification rates for Logistic Regression
rda.rates.train <- cbind(rate1.train,rate3.train,rate5.train)
rda.rates.train
rda.rates.test <- cbind(rate2.test,rate4.test,rate6.test)
rda.rates.test
```

# Boosting before variable selection

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, eval=T}

#run boosting
start.time <- proc.time()

boost.seismic =gbm(class~.,data=seismic.train, distribution="bernoulli",n.trees =5000, interaction.depth =4)

total.time <- proc.time() - start.time
time8 <- total.time[3] 
time8

#summary(boost.seismic)

###marginal effect of the selected variables on the response
par(mfrow =c(1,2))
plot(boost.seismic ,i="genergy")
plot(boost.seismic ,i="energy")

#predict on the train dataset
yhat.boost.train=predict (boost.seismic,newdata =seismic.train,n.trees =5000,type="response")
#yhat.boost.train

#round to 0 and 1
yhat.boost.train.round=round(yhat.boost.train)
#yhat.boost.train.round

#roc curve on train dataset

roc.Train <- roc(seismic.train$class, yhat.boost.train.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

#predict on the test dataset
yhat.boost.test=predict (boost.seismic,newdata =seismic.test,n.trees =5000,type="response")
#yhat.boost.test

#round to 0 and 1
yhat.boost.test.round=round(yhat.boost.test)
#yhat.boost.test.round

#roc curve on test dataset

roc.Train <- roc(seismic.test$class, yhat.boost.test.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

## confusion table on Test Data 
#confusion <- table(yhat.boost.test.round, seismic.test$class)
#sensitivity <- confusion[2,2]/sum(confusion[,2])
#specificity <- confusion[1,1]/sum(confusion[,1])
#mean((yhat.rf.train - seismic.train$class)^2)
#sensitivity
#specificity
#train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
#train.accuracy

```

#Boosting after variable selection

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, eval=T}
#--------------------------------------------------------
## Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
#--------------------------------------------------------

start.time <- proc.time()

boost.seismic =gbm(class~genergy + gpuls + nbumps + nbumps2 + nbumps4,data=seismic.train, distribution="bernoulli",n.trees =5000, interaction.depth =4)

total.time <- proc.time() - start.time
time9 <- total.time[3] 
time9

#summary(boost.seismic)

#predict on the train dataset
yhat.boost.train=predict (boost.seismic,newdata =seismic.train,n.trees =5000,type="response")
#yhat.boost.train

#round to 0 and 1
yhat.boost.train.round=round(yhat.boost.train)
#yhat.boost.train.round

#roc curve on train dataset

roc.Train <- roc(seismic.train$class, yhat.boost.train.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

#predict on the test dataset
yhat.boost.test=predict (boost.seismic,newdata =seismic.test,n.trees =5000,type="response")
#yhat.boost.test

#round to 0 and 1
yhat.boost.test.round=round(yhat.boost.test)
#yhat.boost.test.round

#roc curve on test dataset

roc.Train <- roc(seismic.test$class, yhat.boost.test.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

## confusion table on Test Data 
#confusion <- table(yhat.boost.test.round, seismic.test$class)
#sensitivity <- confusion[2,2]/sum(confusion[,2])
#specificity <- confusion[1,1]/sum(confusion[,1])

#sensitivity
#specificity
#train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
#train.accuracy

```


```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, eval=F}
#-------------------------------------- 
## Model 2 = seismic+shift+gpuls+nbumps
#--------------------------------------

start.time <- proc.time()

boost.seismic =gbm(class~seismic+shift+gpuls+nbumps,data=seismic.train, distribution="bernoulli",n.trees =5000, interaction.depth =4)

total.time <- proc.time() - start.time
time9 <- total.time[3] 
time9

#summary(boost.seismic)

#predict on the train dataset
yhat.boost.train=predict (boost.seismic,newdata =seismic.train,n.trees =5000,type="response")
#yhat.boost.train

#round to 0 and 1
yhat.boost.train.round=round(yhat.boost.train)
#yhat.boost.train.round

#roc curve on train dataset

roc.Train <- roc(seismic.train$class, yhat.boost.train.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

#predict on the test dataset
yhat.boost.test=predict (boost.seismic,newdata =seismic.test,n.trees =5000,type="response")
#yhat.boost.test

#round to 0 and 1
yhat.boost.test.round=round(yhat.boost.test)
#yhat.boost.test.round

#roc curve on test dataset
roc.Train <- roc(seismic.test$class, yhat.boost.test.round, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Test ROC for Boosting Classification", xlab = "False Positive Rate", ylab = "True Positive Rate",print.auc = TRUE)

## confusion table on Test Data 
#confusion <- table(yhat.boost.test.round, seismic.test$class)
#sensitivity <- confusion[2,2]/sum(confusion[,2])
#specificity <- confusion[1,1]/sum(confusion[,1])

#sensitivity
#specificity
#train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
#train.accuracy
```

# Random Forests Classification  

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

## Setting data again for RF classifcation, as response variable has to be converted into "categorical" 
seismic <- read.csv("seismic.csv")
par(mfrow=c(1,2))
seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}

# Make response variable "categorical" for RF classification 
seismic$class = as.factor(seismic$class)

# Setting train and test dataset 
n <- dim(seismic)[1]
p <- dim(seismic)[2]
set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]
```

## RF Classification BEFORE Variable Selection 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

start.time <- proc.time()
#------------------------------------------------------------------------------
## Tune the RF: Finding optimul numbers of variables for splitting on each node
#------------------------------------------------------------------------------
bestmtry <- tuneRF(seismic.train[-16], seismic.train$class, ntreeTry=100, 
     stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE, dobest=FALSE)

## RF on Training Data 

rf.seismic = randomForest(class~., data = seismic.train, mtry=2, ntree=1000, importance = TRUE)
yhat.rf.train = predict(rf.seismic, type = "prob", newdata = seismic.train)[,2]

roc.Train <- roc(seismic.train$class, yhat.rf.train, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Train ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

#rf.pred = prediction(yhat.rf.train, seismic.train$class)
#rf.perf = performance(rf.pred,"tpr","fpr")
#par(mfrow = c(1,2))
#plot(rf.perf, main="ROC Curve for Random Forest", print.auc=TRUE, col=2, lwd=2)
#abline(a=0,b=1,lwd=2,lty=2,col="gray", print.auc=TRUE)

confusion <- table(yhat.rf.train, seismic.train$class)
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])
#mean((yhat.rf.train - seismic.train$class)^2)
sensitivity
specificity
train.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.train)
train.accuracy

## RF on Test Data 

yhat.rf.test = predict(rf.seismic, type = "prob", newdata = seismic.test)[,2]
roc.test <- roc(seismic.test$class, yhat.rf.test, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.test, col = "blue", auc.polygon = TRUE, main = "Test ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

confusion <- table(yhat.rf.test, seismic.test$class)
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])
#mean((yhat.rf.test - seismic.test$class)^2)
sensitivity
specificity
test.accuracy = (confusion[1,1]+confusion[2,2])/nrow(seismic.test)
test.accuracy

importance(rf.seismic)
varImpPlot(rf.seismic)

```

## RF Classification AFTER Variable Selection 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

#--------------------------------------------------------
## Model 1 = genergy + gpuls + nbumps + nbumps2 + nbumps4
#--------------------------------------------------------

## RF on Training Data
rf.seismic = randomForest(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic.train, mtry=2, ntree=1000, importance = TRUE)
yhat.rf.train = predict(rf.seismic, type = "prob", newdata = seismic.train)[,2]
roc.Train <- roc(seismic.train$class, yhat.rf.train, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Model 1: Train ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)


## RF on Test Data
yhat.rf.test = predict(rf.seismic, type = "prob", newdata = seismic.test)[,2]
roc.test <- roc(seismic.test$class, yhat.rf.test, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.test, col = "blue", auc.polygon = TRUE, main = "Model 1: Test ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

importance(rf.seismic)
varImpPlot(rf.seismic)

#-------------------------------------- 
## Model 2 = seismic+shift+gpuls+nbumps
#--------------------------------------

## RF on Training Data
rf.seismic = randomForest(class~seismic+shift+gpuls+nbumps, data = seismic.train, mtry=2, ntree=1000, importance = TRUE)
yhat.rf.train = predict(rf.seismic, type = "prob", newdata = seismic.train)[,2]
roc.Train <- roc(seismic.train$class, yhat.rf.train, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.Train, col = "blue", auc.polygon = TRUE, main = "Model 2: Train ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)


## RF on Test Data
yhat.rf.test = predict(rf.seismic, type = "prob", newdata = seismic.test)[,2]
roc.test <- roc(seismic.test$class, yhat.rf.test, direction = "<")
par(mfrow = c(1,2))
plot.roc(roc.test, col = "blue", auc.polygon = TRUE, main = "Model 2: Test ROC for RF Classification", xlab = "False Positive Rate", ylab = "True Positive Rate", print.auc = TRUE)

importance(rf.seismic)
varImpPlot(rf.seismic)


total.time <- proc.time() - start.time
time7 <- total.time[3] 
```

# Support vector classifier and support vector machine

```{r}
# Variable selection and refitting
#model1 = genergy + gpuls + nbumps + nbumps2 + nbumps4 #Step
#model2 = seismic + shift + gpuls + nbumps #Lasso

library(e1071)

# We can modify this by using kernel = radial, which involves changing choice of gamma
# or by choosing kernel = polynomial, where we can also modify the degree
# Using a linear kernel is technically a support vector classifier

#--------------------------------------------------
# Get the ROC curve for svm
library(ROCR)

rocplot <- function(pred, truth, ...){
  predob <- prediction(pred, truth)
  perf <- performance(predob, "tpr", "fpr")
  plot(perf,...)
}
#--------------------------------------------------

#--------------------------------------------------
# Start with just the linear kernel
#--------------------------------------------------

##
## Model 1
##

start.time <- proc.time()

tune.out <- tune(svm, factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "linear", ranges = list(cost = c(.001,.01,.1,1,5)))

# Look for a best model
summary(tune.out)
bestmod <- tune.out$best.model
summary(bestmod)

ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmfit.best1 <- svm(factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "linear", cost = bestmod$cost, decision.values = T)
fitted1 <- attributes(predict(svmfit.best1, seismic[train,], decision.values = T))$decision.values
fitted.test1 <- attributes(predict(svmfit.best1, seismic[-train,], decision.values = T))$decision.values

# It is unsurprising that this doesn't work well, because we are using a linear classifier
# However, we have reason to believe that a non-linear classifier would be more appropriate
rocplot(fitted1, seismic[train,"class"], main = "Training data")
rocplot(fitted.test1, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time1 <- total.time[3]

##
## Model 2
##

start.time <- proc.time()

tune.out <- tune(svm, factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "linear", ranges = list(cost = c(.001,.01,.1,1,5)))

# Look for a best model
summary(tune.out)
bestmod <- tune.out$best.model
summary(bestmod)

ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmfit.best2 <- svm(factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "linear", cost = bestmod$cost, decision.values = T)
fitted2 <- attributes(predict(svmfit.best2, seismic[train,], decision.values = T))$decision.values
fitted.test2 <- attributes(predict(svmfit.best2, seismic[-train,], decision.values = T))$decision.values

# This one shows a much better ROC curve
# But it still looks bad just from the original table produced
rocplot(fitted2, seismic[train,"class"], main = "Training data")
rocplot(fitted.test2, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time2 <- total.time[3]

#--------------------------------------------------
# Implement with the radial kernel
#--------------------------------------------------

##
## Model 1
##

start.time <- proc.time()

tune.out2 <- tune(svm, factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "radial", ranges = list(cost = c(.001,.01,.1), gamma = c(1,5,50)))

bestmod <- tune.out2$best.model
ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmrad2 <- svm(factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "radial", gamma = tune.out2$best.model$gamma, cost = tune.out2$best.model$cost, decision.values = T)
fitted2 <- attributes(predict(svmrad2, seismic[train,], decision.values = T))$decision.values
fitted.test2 <- attributes(predict(svmrad2, seismic[-train,],decision.values = T))$decision.values

rocplot(fitted2, seismic[train,"class"], main = "Training data")
rocplot(fitted.test2, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time3 <- total.time[3]

##
## Model 2
##

start.time <- proc.time()

tune.out3 <- tune(svm, factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "radial", ranges = list(cost = c(.001,.01,.1), gamma = c(1,5,50)))

bestmod <- tune.out3$best.model
ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmrad3 <- svm(factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "radial", gamma = tune.out3$best.model$gamma, cost = tune.out3$best.model$cost, decision.values = T)
fitted3 <- attributes(predict(svmrad3, seismic[train,], decision.values = T))$decision.values
fitted.test3 <- attributes(predict(svmrad3, seismic[-train,],decision.values = T))$decision.values

rocplot(fitted3, seismic[train,"class"], main = "Training data")
rocplot(fitted.test3, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time4 <- total.time[3]

#--------------------------------------------------
# Implement with the polynomial kernel
#--------------------------------------------------

##
## Model 1
##

start.time <- proc.time()

tune.out4 <- tune(svm, factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "polynomial", ranges = list(cost = c(.001,.01,.1), degree = c(2,3,4)))

bestmod <- tune.out4$best.model
ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmpoly4 <- svm(factor(class)~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic[train,], kernel = "polynomial", cost = tune.out4$best.model$cost, degree = tune.out4$best.model$degree, decision.values = T)
fitted4 <- attributes(predict(svmpoly4, seismic[train,], decision.values = T))$decision.values
fitted.test4 <- attributes(predict(svmpoly4, seismic[-train,],decision.values = T))$decision.values

rocplot(fitted4, seismic[train,"class"], main = "Training data")
rocplot(fitted.test4, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time5 <- total.time[3]

##
## Model 2
##

start.time <- proc.time()

tune.out5 <- tune(svm, factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "polynomial", ranges = list(cost = c(.001,.01,.1), degree = c(2,3,4)))

bestmod <- tune.out5$best.model
ypred <- predict(bestmod, seismic[-train,])
table(predict = ypred, truth = seismic$class[-train])

svmpoly5 <- svm(factor(class)~seismic + shift + gpuls + nbumps, data = seismic[train,], kernel = "polynomial", cost = tune.out5$best.model$cost, degree = tune.out5$best.model$degree, decision.values = T)
fitted5 <- attributes(predict(svmpoly5, seismic[train,], decision.values = T))$decision.values
fitted.test5 <- attributes(predict(svmpoly5, seismic[-train,],decision.values = T))$decision.values

rocplot(fitted5, seismic[train,"class"], main = "Training data")
rocplot(fitted.test5, seismic[-train,"class"], main = "Test data")

total.time <- proc.time() - start.time
time6 <- total.time[3]

```

# How to time your code!!!

```{r}
#-------------------------------------
# How to time your method
#-------------------------------------

# Put this before your method
start.time <- proc.time()

## the thing you are computing, like random forest or SVM goes here ##

total.time <- proc.time() - start.time

total.time[3] # the elapsed time

```
